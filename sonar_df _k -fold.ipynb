{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT : SONAR.CSV CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data set (pandas)\n",
    "\n",
    "1) Label Encoding (pandas)\n",
    "\n",
    "2) shufle dataset (pandas)\n",
    "\n",
    "3) split training (60) validation (20) and test (20) %\n",
    "\n",
    "4) Split inputs and labels (output)\n",
    "\n",
    "5) label one hot coding\n",
    "\n",
    "6) fit model without validation (compare training and testing acuracies)\n",
    "\n",
    "7) fit model wit validation (with history)\n",
    "\n",
    "8) create graph\n",
    "\n",
    "9) Introduce k-fold, as data is limited\n",
    "\n",
    "10) tune nework accuracy by ephoc numbers, change of optimizer,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1 : Load all the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_df = pd.read_csv(r\"C:\\Users\\Waleed\\Desktop\\zain piaic files\\piaic-datascience-teaching-master\\piaic-datascience-teaching-master\\PIAIC-Sir-Anees-Quarter-2\\dataset\\sonar.csv\", header=None)#header none function its change 1st index raw its start zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_df.head()\n",
    "#print(sonar_df)\n",
    "#display(sonar_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "print(len(sonar_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Step :shufle dataset (pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.1065</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0907</td>\n",
       "      <td>0.2107</td>\n",
       "      <td>0.3597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.3513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>0.1124</td>\n",
       "      <td>0.1787</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.2682</td>\n",
       "      <td>0.2058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "27   0.0177  0.0300  0.0288  0.0394  0.0630  0.0526  0.0688  0.0633  0.0624   \n",
       "100  0.0629  0.1065  0.1526  0.1229  0.1437  0.1190  0.0884  0.0907  0.2107   \n",
       "6    0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n",
       "7    0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n",
       "140  0.0412  0.1135  0.0518  0.0232  0.0646  0.1124  0.1787  0.2407  0.2682   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "27   0.0613  ...  0.0102  0.0122  0.0044  0.0075  0.0124  0.0099  0.0057   \n",
       "100  0.3597  ...  0.0089  0.0262  0.0108  0.0138  0.0187  0.0230  0.0057   \n",
       "6    0.3513  ...  0.0201  0.0248  0.0131  0.0070  0.0138  0.0092  0.0143   \n",
       "7    0.2838  ...  0.0081  0.0120  0.0045  0.0121  0.0097  0.0085  0.0047   \n",
       "140  0.2058  ...  0.0376  0.0143  0.0272  0.0127  0.0166  0.0095  0.0225   \n",
       "\n",
       "         58      59  60  \n",
       "27   0.0032  0.0019   R  \n",
       "100  0.0113  0.0131   M  \n",
       "6    0.0036  0.0103   R  \n",
       "7    0.0048  0.0053   R  \n",
       "140  0.0098  0.0085   M  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_df.sample(frac=1).head()#sample function select randomly select any two line[ means return all rows (in random order)].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sonar_df = sonar_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = sonar_df[sonar_df.columns[len(sonar_df.columns)-1]]#check length dtype and colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      M\n",
       "2      M\n",
       "3      R\n",
       "4      R\n",
       "      ..\n",
       "203    R\n",
       "204    R\n",
       "205    R\n",
       "206    M\n",
       "207    M\n",
       "Name: 60, Length: 208, dtype: object"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label = sonar_df.iloc[:,-7:]\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### converting column to flatten array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'M' 'M' 'R' 'R' 'M' 'R' 'M' 'R' 'R' 'R' 'M' 'M' 'M' 'R' 'M' 'R' 'M'\n",
      " 'M' 'R' 'R' 'R' 'R' 'M' 'M' 'R' 'M' 'M' 'M' 'R' 'R' 'R' 'M' 'R' 'R' 'R'\n",
      " 'R' 'R' 'R' 'M' 'M' 'M' 'R' 'M' 'M' 'M' 'M' 'R' 'R' 'R' 'M' 'M' 'M' 'R'\n",
      " 'R' 'M' 'R' 'R' 'M' 'M' 'R' 'M' 'M' 'M' 'R' 'M' 'R' 'R' 'R' 'M' 'R' 'M'\n",
      " 'M' 'R' 'M' 'M' 'M' 'R' 'R' 'R' 'M' 'M' 'M' 'R' 'M' 'R' 'R' 'M' 'M' 'M'\n",
      " 'R' 'M' 'M' 'R' 'M' 'R' 'M' 'M' 'R' 'M' 'M' 'R' 'M' 'M' 'R' 'R' 'M' 'M'\n",
      " 'R' 'M' 'M' 'R' 'M' 'M' 'R' 'M' 'M' 'R' 'R' 'R' 'R' 'R' 'R' 'M' 'M' 'R'\n",
      " 'R' 'R' 'M' 'M' 'M' 'R' 'R' 'M' 'M' 'M' 'M' 'M' 'M' 'R' 'R' 'R' 'M' 'M'\n",
      " 'M' 'M' 'M' 'R' 'R' 'M' 'R' 'R' 'R' 'M' 'R' 'M' 'M' 'R' 'M' 'R' 'R' 'M'\n",
      " 'R' 'M' 'R' 'R' 'M' 'R' 'M' 'R' 'M' 'M' 'M' 'M' 'M' 'M' 'R' 'R' 'R' 'R'\n",
      " 'M' 'R' 'M' 'R' 'M' 'M' 'M' 'R' 'R' 'M' 'R' 'R' 'R' 'R' 'M' 'M' 'M' 'M'\n",
      " 'M' 'R' 'M' 'M' 'M' 'R' 'R' 'R' 'M' 'M']\n"
     ]
    }
   ],
   "source": [
    "label = np.ravel(label)#its show hows random and real\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split inputs and labels (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "#le.fit_transform(label,label)\n",
    "label = le.fit_transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1\n",
      " 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1\n",
      " 0 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0\n",
      " 1 0 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1\n",
      " 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0\n",
      " 0 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(type(label))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "label = label.astype('float')#because it float type data\n",
    "#print(label)\n",
    "print(type(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.1543</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.1838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.1218</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.2531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>0.1038</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0654  0.0649  0.0737  0.1132  0.2482  0.1257  0.1797  0.0989  0.2460   \n",
       "1    0.0428  0.0555  0.0708  0.0618  0.1215  0.1524  0.1543  0.0391  0.0610   \n",
       "2    0.0209  0.0278  0.0115  0.0445  0.0427  0.0766  0.1458  0.1430  0.1894   \n",
       "3    0.0311  0.0491  0.0692  0.0831  0.0079  0.0200  0.0981  0.1016  0.2025   \n",
       "4    0.0235  0.0291  0.0749  0.0519  0.0227  0.0834  0.0677  0.2002  0.2876   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0093  0.0269  0.0217  0.0339  0.0305  0.1172  0.1450  0.0638  0.0740   \n",
       "204  0.0109  0.0093  0.0121  0.0378  0.0679  0.0863  0.1004  0.0664  0.0941   \n",
       "205  0.0664  0.0575  0.0842  0.0372  0.0458  0.0771  0.0771  0.1130  0.2353   \n",
       "206  0.0249  0.0119  0.0277  0.0760  0.1218  0.1538  0.1192  0.1229  0.2119   \n",
       "207  0.0156  0.0210  0.0282  0.0596  0.0462  0.0779  0.1365  0.0780  0.1038   \n",
       "\n",
       "         9   ...      50      51      52      53      54      55      56  \\\n",
       "0    0.3422  ...  0.0243  0.0210  0.0361  0.0239  0.0447  0.0394  0.0355   \n",
       "1    0.0113  ...  0.0009  0.0142  0.0179  0.0079  0.0060  0.0131  0.0089   \n",
       "2    0.1853  ...  0.0133  0.0096  0.0014  0.0049  0.0039  0.0029  0.0078   \n",
       "3    0.0767  ...  0.0089  0.0087  0.0032  0.0130  0.0188  0.0101  0.0229   \n",
       "4    0.3674  ...  0.0242  0.0083  0.0037  0.0095  0.0105  0.0030  0.0132   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.1360  ...  0.0309  0.0212  0.0091  0.0056  0.0086  0.0092  0.0070   \n",
       "204  0.1036  ...  0.0124  0.0077  0.0023  0.0117  0.0053  0.0077  0.0076   \n",
       "205  0.1838  ...  0.0135  0.0141  0.0190  0.0043  0.0036  0.0026  0.0024   \n",
       "206  0.2531  ...  0.0140  0.0027  0.0068  0.0150  0.0012  0.0133  0.0048   \n",
       "207  0.1567  ...  0.0189  0.0150  0.0060  0.0082  0.0091  0.0038  0.0056   \n",
       "\n",
       "         57      58      59  \n",
       "0    0.0440  0.0243  0.0098  \n",
       "1    0.0084  0.0113  0.0049  \n",
       "2    0.0047  0.0021  0.0011  \n",
       "3    0.0182  0.0046  0.0038  \n",
       "4    0.0068  0.0108  0.0090  \n",
       "..      ...     ...     ...  \n",
       "203  0.0116  0.0060  0.0110  \n",
       "204  0.0056  0.0055  0.0039  \n",
       "205  0.0162  0.0109  0.0079  \n",
       "206  0.0244  0.0077  0.0074  \n",
       "207  0.0056  0.0048  0.0024  \n",
       "\n",
       "[208 rows x 60 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variety = sonar_df.iloc[:, :-1]# we create new varible in sonar_df  \n",
    "variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[0.0654 0.0649 0.0737 ... 0.044  0.0243 0.0098]\n",
      " [0.0428 0.0555 0.0708 ... 0.0084 0.0113 0.0049]\n",
      " [0.0209 0.0278 0.0115 ... 0.0047 0.0021 0.0011]\n",
      " ...\n",
      " [0.0664 0.0575 0.0842 ... 0.0162 0.0109 0.0079]\n",
      " [0.0249 0.0119 0.0277 ... 0.0244 0.0077 0.0074]\n",
      " [0.0156 0.021  0.0282 ... 0.0056 0.0048 0.0024]]\n"
     ]
    }
   ],
   "source": [
    "print(type(variety))\n",
    "variety = variety.values\n",
    "print(type(variety))\n",
    "print(variety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 60)\n",
      "(208,)\n"
     ]
    }
   ],
   "source": [
    "print(variety.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 :split training (70) validation (10) and test (20) %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    " #first split variety and label \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(variety, label, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then spliting x_train y_train test size \n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.125, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print  train and test shape test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : (145, 60)\n",
      "train label : (145,)\n",
      "test : (42, 60)\n",
      "test label: (42,)\n",
      "validation : (21, 60)\n",
      "validation label : (21,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train :\",x_train.shape)\n",
    "print(\"train label :\",y_train.shape)\n",
    "print(\"test :\",x_test.shape)\n",
    "print(\"test label:\",y_test.shape)\n",
    "print(\"validation :\",x_val.shape)\n",
    "print(\"validation label :\",y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now traning validation \n",
    "\n",
    "\n",
    "(chapter 3: Listing Listing 3.9, 3:11, 3:17, 3:18 3:19, 3:20)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_Validation(batch_size,epochs,drop_ratio):\n",
    "    print(\"batch_size :\",batch_size,\"\\n\",\"epochs :\",epochs,\"\\n\",\"drop_ratio :\",drop_ratio) \n",
    "  \n",
    "    #bulid neural network\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(60,)),\n",
    "    tf.keras.layers.Dropout(drop_ratio),\n",
    "    tf.keras.layers.Dense(48, activation='relu'),\n",
    "    tf.keras.layers.Dense(12, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation=\"relu\"),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')])# softmax # sigmoid])\n",
    "    \n",
    "    \n",
    "    #Compilation Step\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # fit model wit validation (with history)\n",
    "    \n",
    "    history = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_val, y_val))\n",
    "    \n",
    "    \n",
    "    # evalution step\n",
    "    evaluation = model.evaluate(x_test,  y_test,batch_size=batch_size, verbose=2)\n",
    "    print()\n",
    "    print(\"Test loss :\",evaluation[0]*100,\"%\")\n",
    "    print(\"Test accuracy :\",evaluation[1]*100,\"%\")\n",
    "    \n",
    "    \n",
    "    #Plotting the training and validation loss\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    #Step 8: create graph\n",
    "    \n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Test loss :\",evaluation[0]*100,\"%\")\n",
    "    print(\"Test accuracy :\",evaluation[1]*100,\"%\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 512 #256  #128\n",
    "epochs = 70 # 230\n",
    "drop_ratio = 0.002 #0.02 #0.03 #0.04 # 0.03  #0.001\n",
    "#training_Validation(batch_size,epochs,drop_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size : 128 \n",
      " epochs : 70 \n",
      " drop_ratio : 0.002\n",
      "Train on 145 samples, validate on 21 samples\n",
      "Epoch 1/70\n",
      "145/145 [==============================] - 2s 11ms/sample - loss: 0.6977 - accuracy: 0.4621 - val_loss: 0.6927 - val_accuracy: 0.5238\n",
      "Epoch 2/70\n",
      "145/145 [==============================] - 0s 290us/sample - loss: 0.6880 - accuracy: 0.5724 - val_loss: 0.6810 - val_accuracy: 0.6667\n",
      "Epoch 3/70\n",
      "145/145 [==============================] - 0s 393us/sample - loss: 0.6821 - accuracy: 0.4828 - val_loss: 0.6795 - val_accuracy: 0.6190\n",
      "Epoch 4/70\n",
      "145/145 [==============================] - 0s 248us/sample - loss: 0.6753 - accuracy: 0.5310 - val_loss: 0.6832 - val_accuracy: 0.6667\n",
      "Epoch 5/70\n",
      "145/145 [==============================] - 0s 366us/sample - loss: 0.6738 - accuracy: 0.7034 - val_loss: 0.6770 - val_accuracy: 0.7143\n",
      "Epoch 6/70\n",
      "145/145 [==============================] - 0s 255us/sample - loss: 0.6682 - accuracy: 0.6483 - val_loss: 0.6636 - val_accuracy: 0.6667\n",
      "Epoch 7/70\n",
      "145/145 [==============================] - 0s 366us/sample - loss: 0.6639 - accuracy: 0.5448 - val_loss: 0.6512 - val_accuracy: 0.7143\n",
      "Epoch 8/70\n",
      "145/145 [==============================] - 0s 248us/sample - loss: 0.6624 - accuracy: 0.4897 - val_loss: 0.6475 - val_accuracy: 0.7143\n",
      "Epoch 9/70\n",
      "145/145 [==============================] - 0s 400us/sample - loss: 0.6562 - accuracy: 0.5103 - val_loss: 0.6549 - val_accuracy: 0.7619\n",
      "Epoch 10/70\n",
      "145/145 [==============================] - 0s 297us/sample - loss: 0.6489 - accuracy: 0.6069 - val_loss: 0.6657 - val_accuracy: 0.7619\n",
      "Epoch 11/70\n",
      "145/145 [==============================] - 0s 628us/sample - loss: 0.6479 - accuracy: 0.7103 - val_loss: 0.6690 - val_accuracy: 0.7143\n",
      "Epoch 12/70\n",
      "145/145 [==============================] - ETA: 0s - loss: 0.6455 - accuracy: 0.71 - 0s 538us/sample - loss: 0.6457 - accuracy: 0.7241 - val_loss: 0.6596 - val_accuracy: 0.8095\n",
      "Epoch 13/70\n",
      "145/145 [==============================] - 0s 248us/sample - loss: 0.6385 - accuracy: 0.7034 - val_loss: 0.6363 - val_accuracy: 0.8095\n",
      "Epoch 14/70\n",
      "145/145 [==============================] - 0s 366us/sample - loss: 0.6339 - accuracy: 0.6345 - val_loss: 0.6200 - val_accuracy: 0.7143\n",
      "Epoch 15/70\n",
      "145/145 [==============================] - 0s 338us/sample - loss: 0.6374 - accuracy: 0.5379 - val_loss: 0.6212 - val_accuracy: 0.7619\n",
      "Epoch 16/70\n",
      "145/145 [==============================] - 0s 221us/sample - loss: 0.6285 - accuracy: 0.6069 - val_loss: 0.6358 - val_accuracy: 0.8095\n",
      "Epoch 17/70\n",
      "145/145 [==============================] - 0s 310us/sample - loss: 0.6234 - accuracy: 0.6897 - val_loss: 0.6446 - val_accuracy: 0.7619\n",
      "Epoch 18/70\n",
      "145/145 [==============================] - 0s 214us/sample - loss: 0.6219 - accuracy: 0.7379 - val_loss: 0.6393 - val_accuracy: 0.7619\n",
      "Epoch 19/70\n",
      "145/145 [==============================] - 0s 269us/sample - loss: 0.6189 - accuracy: 0.7517 - val_loss: 0.6250 - val_accuracy: 0.8095\n",
      "Epoch 20/70\n",
      "145/145 [==============================] - 0s 200us/sample - loss: 0.6126 - accuracy: 0.6966 - val_loss: 0.6088 - val_accuracy: 0.7143\n",
      "Epoch 21/70\n",
      "145/145 [==============================] - 0s 207us/sample - loss: 0.6080 - accuracy: 0.6759 - val_loss: 0.6043 - val_accuracy: 0.7143\n",
      "Epoch 22/70\n",
      "145/145 [==============================] - 0s 283us/sample - loss: 0.6037 - accuracy: 0.6690 - val_loss: 0.6120 - val_accuracy: 0.8095\n",
      "Epoch 23/70\n",
      "145/145 [==============================] - 0s 193us/sample - loss: 0.5995 - accuracy: 0.7172 - val_loss: 0.6209 - val_accuracy: 0.7619\n",
      "Epoch 24/70\n",
      "145/145 [==============================] - 0s 317us/sample - loss: 0.5997 - accuracy: 0.7586 - val_loss: 0.6130 - val_accuracy: 0.7619\n",
      "Epoch 25/70\n",
      "145/145 [==============================] - 0s 193us/sample - loss: 0.5941 - accuracy: 0.7379 - val_loss: 0.5922 - val_accuracy: 0.7619\n",
      "Epoch 26/70\n",
      "145/145 [==============================] - 0s 290us/sample - loss: 0.5905 - accuracy: 0.6897 - val_loss: 0.5808 - val_accuracy: 0.6667\n",
      "Epoch 27/70\n",
      "145/145 [==============================] - 0s 193us/sample - loss: 0.5937 - accuracy: 0.6345 - val_loss: 0.5786 - val_accuracy: 0.7619\n",
      "Epoch 28/70\n",
      "145/145 [==============================] - ETA: 0s - loss: 0.5775 - accuracy: 0.67 - 0s 179us/sample - loss: 0.5846 - accuracy: 0.6621 - val_loss: 0.5892 - val_accuracy: 0.8095\n",
      "Epoch 29/70\n",
      "145/145 [==============================] - 0s 331us/sample - loss: 0.5792 - accuracy: 0.7448 - val_loss: 0.6019 - val_accuracy: 0.8095\n",
      "Epoch 30/70\n",
      "145/145 [==============================] - 0s 193us/sample - loss: 0.5791 - accuracy: 0.8000 - val_loss: 0.5925 - val_accuracy: 0.8095\n",
      "Epoch 31/70\n",
      "145/145 [==============================] - 0s 338us/sample - loss: 0.5744 - accuracy: 0.7931 - val_loss: 0.5773 - val_accuracy: 0.8571\n",
      "Epoch 32/70\n",
      "145/145 [==============================] - 0s 241us/sample - loss: 0.5700 - accuracy: 0.7517 - val_loss: 0.5720 - val_accuracy: 0.8095\n",
      "Epoch 33/70\n",
      "145/145 [==============================] - 0s 255us/sample - loss: 0.5648 - accuracy: 0.7655 - val_loss: 0.5689 - val_accuracy: 0.8095\n",
      "Epoch 34/70\n",
      "145/145 [==============================] - 0s 207us/sample - loss: 0.5622 - accuracy: 0.7655 - val_loss: 0.5588 - val_accuracy: 0.8571\n",
      "Epoch 35/70\n",
      "145/145 [==============================] - 0s 241us/sample - loss: 0.5575 - accuracy: 0.7724 - val_loss: 0.5480 - val_accuracy: 0.8571\n",
      "Epoch 36/70\n",
      "145/145 [==============================] - 0s 435us/sample - loss: 0.5551 - accuracy: 0.7655 - val_loss: 0.5446 - val_accuracy: 0.8095\n",
      "Epoch 37/70\n",
      "145/145 [==============================] - 0s 469us/sample - loss: 0.5504 - accuracy: 0.7655 - val_loss: 0.5546 - val_accuracy: 0.8095\n",
      "Epoch 38/70\n",
      "145/145 [==============================] - 0s 207us/sample - loss: 0.5472 - accuracy: 0.8138 - val_loss: 0.5492 - val_accuracy: 0.8095\n",
      "Epoch 39/70\n",
      "145/145 [==============================] - 0s 276us/sample - loss: 0.5437 - accuracy: 0.8000 - val_loss: 0.5344 - val_accuracy: 0.8095\n",
      "Epoch 40/70\n",
      "145/145 [==============================] - 0s 200us/sample - loss: 0.5405 - accuracy: 0.7655 - val_loss: 0.5401 - val_accuracy: 0.8095\n",
      "Epoch 41/70\n",
      "145/145 [==============================] - 0s 248us/sample - loss: 0.5378 - accuracy: 0.8000 - val_loss: 0.5475 - val_accuracy: 0.7143\n",
      "Epoch 42/70\n",
      "145/145 [==============================] - 0s 200us/sample - loss: 0.5345 - accuracy: 0.8000 - val_loss: 0.5309 - val_accuracy: 0.8095\n",
      "Epoch 43/70\n",
      "145/145 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.78 - 0s 234us/sample - loss: 0.5323 - accuracy: 0.7793 - val_loss: 0.5237 - val_accuracy: 0.8095\n",
      "Epoch 44/70\n",
      "145/145 [==============================] - 0s 221us/sample - loss: 0.5292 - accuracy: 0.7724 - val_loss: 0.5250 - val_accuracy: 0.8095\n",
      "Epoch 45/70\n",
      "145/145 [==============================] - 0s 228us/sample - loss: 0.5188 - accuracy: 0.7862 - val_loss: 0.5153 - val_accuracy: 0.8095\n",
      "Epoch 46/70\n",
      "145/145 [==============================] - 0s 193us/sample - loss: 0.5207 - accuracy: 0.7586 - val_loss: 0.5102 - val_accuracy: 0.7619\n",
      "Epoch 47/70\n",
      "145/145 [==============================] - 0s 207us/sample - loss: 0.5204 - accuracy: 0.7586 - val_loss: 0.5120 - val_accuracy: 0.8095\n",
      "Epoch 48/70\n",
      "145/145 [==============================] - 0s 214us/sample - loss: 0.5117 - accuracy: 0.8069 - val_loss: 0.5245 - val_accuracy: 0.8095\n",
      "Epoch 49/70\n",
      "145/145 [==============================] - 0s 166us/sample - loss: 0.5097 - accuracy: 0.8483 - val_loss: 0.5285 - val_accuracy: 0.8095\n",
      "Epoch 50/70\n",
      "145/145 [==============================] - 0s 159us/sample - loss: 0.5083 - accuracy: 0.8621 - val_loss: 0.5182 - val_accuracy: 0.7619\n",
      "Epoch 51/70\n",
      "145/145 [==============================] - 0s 179us/sample - loss: 0.5048 - accuracy: 0.8621 - val_loss: 0.5027 - val_accuracy: 0.8095\n",
      "Epoch 52/70\n",
      "145/145 [==============================] - 0s 186us/sample - loss: 0.4969 - accuracy: 0.8276 - val_loss: 0.4912 - val_accuracy: 0.7619\n",
      "Epoch 53/70\n",
      "145/145 [==============================] - 0s 193us/sample - loss: 0.4981 - accuracy: 0.8000 - val_loss: 0.4930 - val_accuracy: 0.8095\n",
      "Epoch 54/70\n",
      "145/145 [==============================] - 0s 179us/sample - loss: 0.4891 - accuracy: 0.8345 - val_loss: 0.5238 - val_accuracy: 0.8095\n",
      "Epoch 55/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 0s 193us/sample - loss: 0.4985 - accuracy: 0.8897 - val_loss: 0.5414 - val_accuracy: 0.8095\n",
      "Epoch 56/70\n",
      "145/145 [==============================] - 0s 172us/sample - loss: 0.5096 - accuracy: 0.8828 - val_loss: 0.5209 - val_accuracy: 0.8095\n",
      "Epoch 57/70\n",
      "145/145 [==============================] - 0s 172us/sample - loss: 0.4922 - accuracy: 0.8897 - val_loss: 0.4899 - val_accuracy: 0.7619\n",
      "Epoch 58/70\n",
      "145/145 [==============================] - 0s 200us/sample - loss: 0.4825 - accuracy: 0.8138 - val_loss: 0.5007 - val_accuracy: 0.7619\n",
      "Epoch 59/70\n",
      "145/145 [==============================] - 0s 179us/sample - loss: 0.5079 - accuracy: 0.7448 - val_loss: 0.4981 - val_accuracy: 0.7619\n",
      "Epoch 60/70\n",
      "145/145 [==============================] - 0s 207us/sample - loss: 0.4961 - accuracy: 0.7517 - val_loss: 0.4903 - val_accuracy: 0.8095\n",
      "Epoch 61/70\n",
      "145/145 [==============================] - 0s 317us/sample - loss: 0.4790 - accuracy: 0.8138 - val_loss: 0.4996 - val_accuracy: 0.8095\n",
      "Epoch 62/70\n",
      "145/145 [==============================] - 0s 297us/sample - loss: 0.4754 - accuracy: 0.8966 - val_loss: 0.4948 - val_accuracy: 0.7619\n",
      "Epoch 63/70\n",
      "145/145 [==============================] - 0s 255us/sample - loss: 0.4717 - accuracy: 0.8828 - val_loss: 0.4891 - val_accuracy: 0.7143\n",
      "Epoch 64/70\n",
      "145/145 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.86 - 0s 200us/sample - loss: 0.4665 - accuracy: 0.8621 - val_loss: 0.4873 - val_accuracy: 0.7619\n",
      "Epoch 65/70\n",
      "145/145 [==============================] - 0s 290us/sample - loss: 0.4676 - accuracy: 0.8000 - val_loss: 0.4819 - val_accuracy: 0.7619\n",
      "Epoch 66/70\n",
      "145/145 [==============================] - 0s 172us/sample - loss: 0.4634 - accuracy: 0.8345 - val_loss: 0.4881 - val_accuracy: 0.8095\n",
      "Epoch 67/70\n",
      "145/145 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.88 - 0s 179us/sample - loss: 0.4638 - accuracy: 0.8828 - val_loss: 0.4904 - val_accuracy: 0.7619\n",
      "Epoch 68/70\n",
      "145/145 [==============================] - 0s 345us/sample - loss: 0.4620 - accuracy: 0.8897 - val_loss: 0.4769 - val_accuracy: 0.8095\n",
      "Epoch 69/70\n",
      "145/145 [==============================] - 0s 297us/sample - loss: 0.4548 - accuracy: 0.8483 - val_loss: 0.4833 - val_accuracy: 0.7619\n",
      "Epoch 70/70\n",
      "145/145 [==============================] - 0s 159us/sample - loss: 0.4635 - accuracy: 0.8069 - val_loss: 0.4788 - val_accuracy: 0.7619\n",
      "42/42 - 0s - loss: 0.5658 - accuracy: 0.6905\n",
      "\n",
      "Test loss : 56.58215284347534 %\n",
      "Test accuracy : 69.04761791229248 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 56.58215284347534 %\n",
      "Test accuracy : 69.04761791229248 %\n"
     ]
    }
   ],
   "source": [
    "training_Validation(batch_size,epochs,drop_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training on (k-fold on,training & Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in training 80%, test 20% test \n",
    "x_train, x_test, y_train, y_test = train_test_split(variety, label, test_size=0.2, random_state=1)\n",
    "\n",
    "def kfold_training_Validation(batch_size,epochs,drop_ratio,split):\n",
    "    print(\"batch_size :\",batch_size,\"\\n\",\"epochs :\",epochs,\"\\n\",\"drop_ratio :\",drop_ratio) \n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, input_shape=(60,)),\n",
    "        tf.keras.layers.Dropout(drop_ratio),\n",
    "        tf.keras.layers.Dense(48, activation='relu'),\n",
    "        tf.keras.layers.Dense(12, activation='relu'),\n",
    "        tf.keras.layers.Dense(6, activation='relu'),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=split)\n",
    "    kf.get_n_splits()\n",
    "    \n",
    "    # K-fold not using correctly\n",
    "    \n",
    "    for train_index, test_index in kf.split(x_train):\n",
    "        x_train1, x_test1 = x_train[train_index], x_train[test_index]\n",
    "        y_train1, y_test1 = y_train[train_index], y_train[test_index] \n",
    "\n",
    "    history = model.fit(x_train1, y_train1,batch_size=batch_size,epochs=epochs,verbose=1)\n",
    "    \n",
    "    \n",
    "    evaluation = model.evaluate(x_test1,  y_test1,batch_size=batch_size, verbose=2)\n",
    "    print()\n",
    "    print(\"Test loss :\",evaluation[0]*100,\"%\")\n",
    "    print(\"Test accuracy :\",evaluation[1]*100,\"%\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size : 128 \n",
      " epochs : 130 \n",
      " drop_ratio : 0.001\n",
      "Train on 139 samples\n",
      "Epoch 1/130\n",
      "139/139 [==============================] - 1s 8ms/sample - loss: 0.6758 - accuracy: 0.5252\n",
      "Epoch 2/130\n",
      "139/139 [==============================] - 0s 1ms/sample - loss: 0.6483 - accuracy: 0.5396\n",
      "Epoch 3/130\n",
      "139/139 [==============================] - 0s 417us/sample - loss: 0.6589 - accuracy: 0.5324\n",
      "Epoch 4/130\n",
      "139/139 [==============================] - 0s 727us/sample - loss: 0.6588 - accuracy: 0.5324\n",
      "Epoch 5/130\n",
      "139/139 [==============================] - 0s 532us/sample - loss: 0.6425 - accuracy: 0.5396\n",
      "Epoch 6/130\n",
      "139/139 [==============================] - 0s 460us/sample - loss: 0.6237 - accuracy: 0.6475\n",
      "Epoch 7/130\n",
      "139/139 [==============================] - 0s 158us/sample - loss: 0.6187 - accuracy: 0.7554\n",
      "Epoch 8/130\n",
      "139/139 [==============================] - 0s 151us/sample - loss: 0.6195 - accuracy: 0.7770\n",
      "Epoch 9/130\n",
      "139/139 [==============================] - 0s 252us/sample - loss: 0.6078 - accuracy: 0.7842\n",
      "Epoch 10/130\n",
      "139/139 [==============================] - 0s 165us/sample - loss: 0.5913 - accuracy: 0.7482\n",
      "Epoch 11/130\n",
      "139/139 [==============================] - 0s 173us/sample - loss: 0.5849 - accuracy: 0.7626\n",
      "Epoch 12/130\n",
      "139/139 [==============================] - 0s 144us/sample - loss: 0.5749 - accuracy: 0.7266\n",
      "Epoch 13/130\n",
      "139/139 [==============================] - 0s 158us/sample - loss: 0.5592 - accuracy: 0.7410\n",
      "Epoch 14/130\n",
      "139/139 [==============================] - 0s 173us/sample - loss: 0.5535 - accuracy: 0.7410\n",
      "Epoch 15/130\n",
      "139/139 [==============================] - 0s 165us/sample - loss: 0.5417 - accuracy: 0.7698\n",
      "Epoch 16/130\n",
      "139/139 [==============================] - 0s 281us/sample - loss: 0.5351 - accuracy: 0.7626\n",
      "Epoch 17/130\n",
      "139/139 [==============================] - 0s 158us/sample - loss: 0.5405 - accuracy: 0.7914\n",
      "Epoch 18/130\n",
      "139/139 [==============================] - 0s 151us/sample - loss: 0.5135 - accuracy: 0.7914\n",
      "Epoch 19/130\n",
      "139/139 [==============================] - 0s 216us/sample - loss: 0.5270 - accuracy: 0.7410\n",
      "Epoch 20/130\n",
      "139/139 [==============================] - 0s 144us/sample - loss: 0.5737 - accuracy: 0.6906\n",
      "Epoch 21/130\n",
      "139/139 [==============================] - 0s 144us/sample - loss: 0.5491 - accuracy: 0.7194\n",
      "Epoch 22/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.5004 - accuracy: 0.7842\n",
      "Epoch 23/130\n",
      "139/139 [==============================] - 0s 273us/sample - loss: 0.5034 - accuracy: 0.8058\n",
      "Epoch 24/130\n",
      "139/139 [==============================] - 0s 209us/sample - loss: 0.5389 - accuracy: 0.7194\n",
      "Epoch 25/130\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.71 - 0s 158us/sample - loss: 0.5300 - accuracy: 0.7266\n",
      "Epoch 26/130\n",
      "139/139 [==============================] - 0s 137us/sample - loss: 0.4931 - accuracy: 0.7770\n",
      "Epoch 27/130\n",
      "139/139 [==============================] - 0s 252us/sample - loss: 0.4779 - accuracy: 0.8201\n",
      "Epoch 28/130\n",
      "139/139 [==============================] - 0s 165us/sample - loss: 0.4769 - accuracy: 0.8201\n",
      "Epoch 29/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.4748 - accuracy: 0.8273\n",
      "Epoch 30/130\n",
      "139/139 [==============================] - 0s 137us/sample - loss: 0.4708 - accuracy: 0.8417\n",
      "Epoch 31/130\n",
      "139/139 [==============================] - 0s 273us/sample - loss: 0.4632 - accuracy: 0.8417\n",
      "Epoch 32/130\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.84 - 0s 187us/sample - loss: 0.4558 - accuracy: 0.8417\n",
      "Epoch 33/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.4501 - accuracy: 0.8345\n",
      "Epoch 34/130\n",
      "139/139 [==============================] - 0s 144us/sample - loss: 0.4502 - accuracy: 0.8273\n",
      "Epoch 35/130\n",
      "139/139 [==============================] - 0s 158us/sample - loss: 0.4605 - accuracy: 0.7770\n",
      "Epoch 36/130\n",
      "139/139 [==============================] - 0s 230us/sample - loss: 0.4433 - accuracy: 0.8058\n",
      "Epoch 37/130\n",
      "139/139 [==============================] - 0s 187us/sample - loss: 0.4297 - accuracy: 0.8489\n",
      "Epoch 38/130\n",
      "139/139 [==============================] - 0s 151us/sample - loss: 0.4707 - accuracy: 0.7626\n",
      "Epoch 39/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.4664 - accuracy: 0.7626\n",
      "Epoch 40/130\n",
      "139/139 [==============================] - 0s 158us/sample - loss: 0.4279 - accuracy: 0.8273\n",
      "Epoch 41/130\n",
      "139/139 [==============================] - 0s 446us/sample - loss: 0.4181 - accuracy: 0.8345\n",
      "Epoch 42/130\n",
      "139/139 [==============================] - 0s 424us/sample - loss: 0.4094 - accuracy: 0.8345\n",
      "Epoch 43/130\n",
      "139/139 [==============================] - 0s 266us/sample - loss: 0.4055 - accuracy: 0.8489\n",
      "Epoch 44/130\n",
      "139/139 [==============================] - 0s 137us/sample - loss: 0.4019 - accuracy: 0.8345\n",
      "Epoch 45/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.3987 - accuracy: 0.8417\n",
      "Epoch 46/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.4001 - accuracy: 0.8273\n",
      "Epoch 47/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.3962 - accuracy: 0.8561\n",
      "Epoch 48/130\n",
      "139/139 [==============================] - 0s 353us/sample - loss: 0.3894 - accuracy: 0.8489\n",
      "Epoch 49/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.3941 - accuracy: 0.8561\n",
      "Epoch 50/130\n",
      "139/139 [==============================] - 0s 137us/sample - loss: 0.3818 - accuracy: 0.8489\n",
      "Epoch 51/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.3753 - accuracy: 0.8633\n",
      "Epoch 52/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.3765 - accuracy: 0.8561\n",
      "Epoch 53/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.3697 - accuracy: 0.8633\n",
      "Epoch 54/130\n",
      "139/139 [==============================] - 0s 237us/sample - loss: 0.3689 - accuracy: 0.8561\n",
      "Epoch 55/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.3660 - accuracy: 0.8633\n",
      "Epoch 56/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.3577 - accuracy: 0.8921\n",
      "Epoch 57/130\n",
      "139/139 [==============================] - 0s 101us/sample - loss: 0.3708 - accuracy: 0.8273\n",
      "Epoch 58/130\n",
      "139/139 [==============================] - 0s 144us/sample - loss: 0.3796 - accuracy: 0.8201\n",
      "Epoch 59/130\n",
      "139/139 [==============================] - 0s 144us/sample - loss: 0.3795 - accuracy: 0.8345\n",
      "Epoch 60/130\n",
      "139/139 [==============================] - 0s 410us/sample - loss: 0.3521 - accuracy: 0.8849\n",
      "Epoch 61/130\n",
      "139/139 [==============================] - 0s 137us/sample - loss: 0.3665 - accuracy: 0.8489\n",
      "Epoch 62/130\n",
      "139/139 [==============================] - 0s 108us/sample - loss: 0.3805 - accuracy: 0.8417\n",
      "Epoch 63/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.3508 - accuracy: 0.8561\n",
      "Epoch 64/130\n",
      "139/139 [==============================] - 0s 173us/sample - loss: 0.3639 - accuracy: 0.8633\n",
      "Epoch 65/130\n",
      "139/139 [==============================] - 0s 158us/sample - loss: 0.3785 - accuracy: 0.8417\n",
      "Epoch 66/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.3369 - accuracy: 0.8777\n",
      "Epoch 67/130\n",
      "139/139 [==============================] - 0s 137us/sample - loss: 0.3593 - accuracy: 0.8417\n",
      "Epoch 68/130\n",
      "139/139 [==============================] - 0s 101us/sample - loss: 0.3466 - accuracy: 0.8489\n",
      "Epoch 69/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.3306 - accuracy: 0.8777\n",
      "Epoch 70/130\n",
      "139/139 [==============================] - 0s 101us/sample - loss: 0.3592 - accuracy: 0.8273\n",
      "Epoch 71/130\n",
      "139/139 [==============================] - 0s 273us/sample - loss: 0.3307 - accuracy: 0.8633\n",
      "Epoch 72/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.3257 - accuracy: 0.8633\n",
      "Epoch 73/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.3192 - accuracy: 0.8633\n",
      "Epoch 74/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.3113 - accuracy: 0.8993\n",
      "Epoch 75/130\n",
      "139/139 [==============================] - 0s 201us/sample - loss: 0.3173 - accuracy: 0.9065\n",
      "Epoch 76/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.3102 - accuracy: 0.9065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.3108 - accuracy: 0.8705\n",
      "Epoch 78/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.3212 - accuracy: 0.8417\n",
      "Epoch 79/130\n",
      "139/139 [==============================] - 0s 94us/sample - loss: 0.3047 - accuracy: 0.8921\n",
      "Epoch 80/130\n",
      "139/139 [==============================] - 0s 216us/sample - loss: 0.3089 - accuracy: 0.9065\n",
      "Epoch 81/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.3090 - accuracy: 0.9065\n",
      "Epoch 82/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.2905 - accuracy: 0.9137\n",
      "Epoch 83/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.3184 - accuracy: 0.8489\n",
      "Epoch 84/130\n",
      "139/139 [==============================] - 0s 137us/sample - loss: 0.3000 - accuracy: 0.8777\n",
      "Epoch 85/130\n",
      "139/139 [==============================] - 0s 309us/sample - loss: 0.3060 - accuracy: 0.8921\n",
      "Epoch 86/130\n",
      "139/139 [==============================] - 0s 367us/sample - loss: 0.3307 - accuracy: 0.8561\n",
      "Epoch 87/130\n",
      "139/139 [==============================] - 0s 367us/sample - loss: 0.3074 - accuracy: 0.9065\n",
      "Epoch 88/130\n",
      "139/139 [==============================] - 0s 144us/sample - loss: 0.2848 - accuracy: 0.9065\n",
      "Epoch 89/130\n",
      "139/139 [==============================] - 0s 108us/sample - loss: 0.2803 - accuracy: 0.9137\n",
      "Epoch 90/130\n",
      "139/139 [==============================] - 0s 158us/sample - loss: 0.2842 - accuracy: 0.9209\n",
      "Epoch 91/130\n",
      "139/139 [==============================] - 0s 101us/sample - loss: 0.2818 - accuracy: 0.8993\n",
      "Epoch 92/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.2792 - accuracy: 0.9137\n",
      "Epoch 93/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.2750 - accuracy: 0.8921\n",
      "Epoch 94/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.2715 - accuracy: 0.9281\n",
      "Epoch 95/130\n",
      "139/139 [==============================] - 0s 144us/sample - loss: 0.2827 - accuracy: 0.8993\n",
      "Epoch 96/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.2694 - accuracy: 0.9209\n",
      "Epoch 97/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.2663 - accuracy: 0.9137\n",
      "Epoch 98/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.2677 - accuracy: 0.8777\n",
      "Epoch 99/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.2558 - accuracy: 0.9137\n",
      "Epoch 100/130\n",
      "139/139 [==============================] - 0s 165us/sample - loss: 0.2529 - accuracy: 0.9281\n",
      "Epoch 101/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.2608 - accuracy: 0.9281\n",
      "Epoch 102/130\n",
      "139/139 [==============================] - 0s 216us/sample - loss: 0.2525 - accuracy: 0.9137\n",
      "Epoch 103/130\n",
      "139/139 [==============================] - 0s 165us/sample - loss: 0.2814 - accuracy: 0.8633\n",
      "Epoch 104/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.2682 - accuracy: 0.8705\n",
      "Epoch 105/130\n",
      "139/139 [==============================] - 0s 108us/sample - loss: 0.2549 - accuracy: 0.9209\n",
      "Epoch 106/130\n",
      "139/139 [==============================] - 0s 180us/sample - loss: 0.2814 - accuracy: 0.8849\n",
      "Epoch 107/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.2496 - accuracy: 0.9209\n",
      "Epoch 108/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.2346 - accuracy: 0.9137\n",
      "Epoch 109/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.2322 - accuracy: 0.9281\n",
      "Epoch 110/130\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.2336 - accuracy: 0.9353\n",
      "Epoch 111/130\n",
      "139/139 [==============================] - 0s 86us/sample - loss: 0.2329 - accuracy: 0.9281\n",
      "Epoch 112/130\n",
      "139/139 [==============================] - 0s 158us/sample - loss: 0.2383 - accuracy: 0.8921\n",
      "Epoch 113/130\n",
      "139/139 [==============================] - 0s 115us/sample - loss: 0.2421 - accuracy: 0.8921\n",
      "Epoch 114/130\n",
      "139/139 [==============================] - 0s 108us/sample - loss: 0.2390 - accuracy: 0.8921\n",
      "Epoch 115/130\n",
      "139/139 [==============================] - 0s 108us/sample - loss: 0.2266 - accuracy: 0.9353\n",
      "Epoch 116/130\n",
      "139/139 [==============================] - 0s 101us/sample - loss: 0.2239 - accuracy: 0.9424\n",
      "Epoch 117/130\n",
      "139/139 [==============================] - 0s 101us/sample - loss: 0.2195 - accuracy: 0.9424\n",
      "Epoch 118/130\n",
      "139/139 [==============================] - 0s 173us/sample - loss: 0.2163 - accuracy: 0.9353\n",
      "Epoch 119/130\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.2391 - accuracy: 0.8849\n",
      "Epoch 120/130\n",
      "139/139 [==============================] - 0s 173us/sample - loss: 0.2438 - accuracy: 0.8777\n",
      "Epoch 121/130\n",
      "139/139 [==============================] - 0s 101us/sample - loss: 0.2250 - accuracy: 0.8849\n",
      "Epoch 122/130\n",
      "139/139 [==============================] - 0s 108us/sample - loss: 0.2004 - accuracy: 0.9424\n",
      "Epoch 123/130\n",
      "139/139 [==============================] - 0s 173us/sample - loss: 0.2002 - accuracy: 0.9496\n",
      "Epoch 124/130\n",
      "139/139 [==============================] - 0s 108us/sample - loss: 0.2013 - accuracy: 0.9496\n",
      "Epoch 125/130\n",
      "139/139 [==============================] - 0s 86us/sample - loss: 0.1961 - accuracy: 0.9424\n",
      "Epoch 126/130\n",
      "139/139 [==============================] - 0s 158us/sample - loss: 0.2027 - accuracy: 0.9353\n",
      "Epoch 127/130\n",
      "139/139 [==============================] - 0s 94us/sample - loss: 0.2064 - accuracy: 0.9353\n",
      "Epoch 128/130\n",
      "139/139 [==============================] - 0s 94us/sample - loss: 0.1989 - accuracy: 0.9424\n",
      "Epoch 129/130\n",
      "139/139 [==============================] - 0s 94us/sample - loss: 0.1970 - accuracy: 0.9209\n",
      "Epoch 130/130\n",
      "139/139 [==============================] - 0s 144us/sample - loss: 0.1850 - accuracy: 0.9424\n",
      "27/27 - 0s - loss: 0.3539 - accuracy: 0.8148\n",
      "\n",
      "Test loss : 35.39317846298218 %\n",
      "Test accuracy : 81.4814805984497 %\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation (K-Fold)\n",
    "batch_size = 128 #512  #128 # 32 , 128 , 256\n",
    "epochs = 130\n",
    "drop_ratio = 0.001 # 0.001    # 0.001, 0.9, 0.75, 0.75, 0.5, 0.5, 0.5\n",
    "split = 6\n",
    "kfold_training_Validation(batch_size,epochs,drop_ratio,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
